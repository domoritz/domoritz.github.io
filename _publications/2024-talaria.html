---
layout: publication
year: 2024
title: "Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference"
authors:
  - Fred Hohman
  - Chaoqun Wang
  - Jinmook Lee
  - Jochen GÃ¶rtler
  - Dominik Moritz
  - Jeffrey P Bigham
  - Zhile Ren
  - Cecile Foret
  - Qi Shan
  - Xiaoyi Zhang
type:
  - Conference
venue: CHI
venue_location: Honolulu, HI
venue_tags:
  - CHI
tags:
  - Machine Learning
  - Visual Analytics
venue_url: https://chi2024.acm.org/
arxiv: "2404.03085"
doi: "10.1145/3613904.3642628"
pdf: https://arxiv.org/pdf/2404.03085.pdf
html: https://arxiv.org/html/2404.03085v1
awards:
  - Best Paper Honorable Mention
---

On-device machine learning (ML) moves computation from the cloud to personal
devices, protecting user privacy and enabling intelligent user experiences.
However, fitting models on devices with limited resources presents a major
technical challenge: practitioners need to optimize models and balance hardware
metrics such as model size, latency, and power. To help practitioners create
efficient ML models, we designed and developed Talaria: a model visualization
and optimization system. Talaria enables practitioners to compile models to
hardware, interactively visualize model statistics, and simulate optimizations
to test the impact on inference metrics. Since its internal deployment two years
ago, we have evaluated Talaria using three methodologies: (1) a log analysis
highlighting its growth of 800+ practitioners submitting 3,600+ models; (2) a
usability survey with 26 users assessing the utility of 20 Talaria features; and
(3) a qualitative interview with the 7 most active users about their experience
using Talaria.
